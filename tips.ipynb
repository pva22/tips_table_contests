{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import numpy as np\n",
    "import sklearn \n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import catboost\n",
    "import lightgbm\n",
    "import xgboost\n",
    "import json \n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/dota2_skill_train.csv', index_col='id')\n",
    "test = pd.read_csv('data/dota2_skill_test.csv', index_col='id')\n",
    "\n",
    "heroes = pd.read_csv('data/dota2_heroes.csv', index_col='hero_id')\n",
    "abilities = pd.read_csv('data/dota2_abilities.csv', index_col='ability_id')\n",
    "items = pd.read_csv('data/dota2_items.csv', index_col='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58217c94992438b89aaeb17ee74bd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "records = []\n",
    "import json\n",
    "i = 0\n",
    "with open('data/dota2_skill_train.jsonlines') as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        record = json.loads(line)\n",
    "        records.append(record)\n",
    "        i+=1\n",
    "        if i == 500:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# damage_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7271937299e14fffa17357973118a5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 13s, sys: 8.86 s, total: 1min 21s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_damage_targets = []\n",
    "\n",
    "with open('data/dota2_skill_train.jsonlines') as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        record = json.loads(line)\n",
    "        \n",
    "        damage_targets = record['damage_targets']\n",
    "        damage_targets['id'] = record['id']\n",
    "        \n",
    "        train_damage_targets.append(damage_targets)\n",
    "train_damage_targets = pd.DataFrame(train_damage_targets).set_index('id').fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a555ae889ff44ba8a5461223af43706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 31.8 s, sys: 1.93 s, total: 33.7 s\n",
      "Wall time: 36.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_damage_targets = []\n",
    "\n",
    "with open('data/dota2_skill_test.jsonlines') as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        record = json.loads(line)\n",
    "        \n",
    "        damage_targets = record['damage_targets']\n",
    "        damage_targets['id'] = record['id']\n",
    "        \n",
    "        test_damage_targets.append(damage_targets)\n",
    "test_damage_targets = pd.DataFrame(test_damage_targets).set_index('id').fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# item_purchase_log, final_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4204cc8d28d4607ade38a973af2444e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b277e5c0171b40739f9dbdd4f081b989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99871), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_items_dict = {}\n",
    "\n",
    "with open('data/dota2_skill_train.jsonlines') as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        record = json.loads(line)\n",
    "        \n",
    "        it = []\n",
    "        for i in record['item_purchase_log']:\n",
    "            it.append(i['item_id'])\n",
    "            \n",
    "        train_items_dict[record['id']] = it\n",
    "\n",
    "train_items_qual_count = pd.DataFrame(index=train_items_dict.keys())\n",
    "\n",
    "d = {}\n",
    "for index, qual in zip(items.index,items.qual):\n",
    "    d[index] = qual\n",
    "    \n",
    "for train_id in tqdm_notebook(train_items_qual_count.index):\n",
    "    x = train_items_dict[train_id]\n",
    "    qual_item = [d[i] for i in x]\n",
    "    for q_i in ['component', 'rare', 'epic', 'consumable', 'artifact', 'common', 'secret_shop']:\n",
    "        train_items_qual_count.at[train_id, 'qual_item_{}_count'.format(q_i)] = qual_item.count(q_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfda78704927492f8bbd53cf66da2e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8867b74b304485b6e2534c40d4aa8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=43265), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_items_dict = {}\n",
    "\n",
    "with open('data/dota2_skill_test.jsonlines') as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        record = json.loads(line)\n",
    "        \n",
    "        it = []\n",
    "        for i in record['item_purchase_log']:\n",
    "            it.append(i['item_id'])\n",
    "            \n",
    "        test_items_dict[record['id']] = it\n",
    "\n",
    "test_items_qual_count = pd.DataFrame(index=test_items_dict.keys())\n",
    "\n",
    "d = {}\n",
    "for index, qual in zip(items.index,items.qual):\n",
    "    d[index] = qual\n",
    "    \n",
    "for test_id in tqdm_notebook(test_items_qual_count.index):\n",
    "    x = test_items_dict[test_id]\n",
    "    qual_item = [d[i] for i in x]\n",
    "    for q_i in ['component', 'rare', 'epic', 'consumable', 'artifact', 'common', 'secret_shop']:\n",
    "        test_items_qual_count.at[test_id, 'qual_item_{}_count'.format(q_i)] = qual_item.count(q_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items_cost_dict = {}\n",
    "for ind, cost in zip(items.index, items.cost):\n",
    "    items_cost_dict[ind] = cost\n",
    "    \n",
    "items_qual_dict = {}\n",
    "for ind, qual in zip(items.index, items.qual):\n",
    "    items_qual_dict[ind] = qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6323ea89cedd4aa193a64f8196653a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_final_items_dict = {}\n",
    "with open('data/dota2_skill_train.jsonlines') as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        record = json.loads(line)\n",
    "        train_final_items_dict[record['id']] = record['final_items']\n",
    "        \n",
    "train_final_items = pd.DataFrame(index=train_final_items_dict.keys())\n",
    "\n",
    "for train_id in tqdm_notebook(train_final_items.index):\n",
    "    \n",
    "    x = train_final_items_dict[train_id]\n",
    "    qual_items = [items_qual_dict[i] for i in x if i != 0]\n",
    "    sum_cost_items = sum([items_cost_dict[i] for i in x if i != 0])\n",
    "    \n",
    "    train_final_items.at[train_id, 'final_items_sum'] = sum_cost_items\n",
    "    for q_i in ['component', 'rare', 'epic', 'consumable', 'artifact', 'common', 'secret_shop']:\n",
    "        train_final_items.at[train_id, 'final_items_{}'.format(q_i)] = qual_items.count(q_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012b9d2abfbb416daa7a688ad110d360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c35a96fe82e4959bb6a09492ae8f2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=43265), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_final_items_dict = {}\n",
    "with open('data/dota2_skill_test.jsonlines') as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        record = json.loads(line)\n",
    "        test_final_items_dict[record['id']] = record['final_items']\n",
    "        \n",
    "test_final_items = pd.DataFrame(index=test_final_items_dict.keys())\n",
    "\n",
    "for test_id in tqdm_notebook(test_final_items.index):\n",
    "    \n",
    "    x = test_final_items_dict[test_id]\n",
    "    qual_items = [items_qual_dict[i] for i in x if i != 0]\n",
    "    sum_cost_items = sum([items_cost_dict[i] for i in x if i != 0])\n",
    "    \n",
    "    test_final_items.at[test_id, 'final_items_sum'] = sum_cost_items\n",
    "    for q_i in ['component', 'rare', 'epic', 'consumable', 'artifact', 'common', 'secret_shop']:\n",
    "        test_final_items.at[test_id, 'final_items_{}'.format(q_i)] = qual_items.count(q_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bbdd1b100a4faeac3d85ffaadd2742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 17s, sys: 5.55 s, total: 2min 22s\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_series = []\n",
    "train_id = []\n",
    "import json\n",
    "it = 0\n",
    "with open('data/dota2_skill_train.jsonlines') as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        record = json.loads(line)\n",
    "        \n",
    "        p = np.array(record['series']['player_gold'])\n",
    "        p_sum = p.sum()\n",
    "        p_mean = p.mean()\n",
    "        p_std = p.std()\n",
    "        p_median = np.median(p)\n",
    "        \n",
    "        t = np.array(record['series']['dire_gold'])\n",
    "        t_sum = t.sum()\n",
    "        t_mean = t.mean()\n",
    "        t_std = t.std()\n",
    "        t_median = np.median(t)\n",
    "        \n",
    "        t1 = np.array(record['series']['radiant_gold'])\n",
    "        t1_sum = t1.sum()\n",
    "        t1_mean = t1.mean()\n",
    "        t1_std = t1.std()\n",
    "        t1_median = np.median(t1)\n",
    "        \n",
    "        \n",
    "        delta_sum =  t_sum - p_sum\n",
    "        delta_mean = t_mean - p_mean\n",
    "        delta_std = t_std - p_std\n",
    "        delta_median = t_median - p_median\n",
    "        \n",
    "        delta1_sum =  t1_sum - p_sum\n",
    "        delta1_mean = t1_mean - p_mean\n",
    "        delta1_std = t1_std - p_std\n",
    "        delta1_median = t1_median - p_median\n",
    "        \n",
    "        \n",
    "        train_id.append(record['id'])\n",
    "        train_series.append([p_sum, p_mean, p_std, p_median, t_sum, t_mean, t_std, t_median, t1_sum, t1_mean, t1_std, t1_median, delta_sum, delta_mean, delta_std, delta_median, delta1_sum, delta1_mean, delta1_std, delta1_median])\n",
    "\n",
    "train_series = pd.DataFrame(train_series, index=train_id)\n",
    "train_series.columns = ['p_sum','p_mean','p_std','p_median','t_sum','t_mean','t_std','t_median', 't1_sum','t1_mean','t1_std','t1_median', 'delta_sum', 'delta_mean', 'delta_std', 'delta_median', 'delta1_sum', 'delta1_mean', 'delta1_std', 'delta1_median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dcc3bd100ed4005a8c1078e9b0d4a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_series = []\n",
    "test_id = []\n",
    "import json\n",
    "it = 0\n",
    "with open('data/dota2_skill_test.jsonlines') as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        record = json.loads(line)\n",
    "        \n",
    "        p = np.array(record['series']['player_gold'])\n",
    "        p_sum = p.sum()\n",
    "        p_mean = p.mean()\n",
    "        p_std = p.std()\n",
    "        p_median = np.median(p)\n",
    "        \n",
    "        t = np.array(record['series']['dire_gold'])\n",
    "        t_sum = t.sum()\n",
    "        t_mean = t.mean()\n",
    "        t_std = t.std()\n",
    "        t_median = np.median(t)\n",
    "        \n",
    "        t1 = np.array(record['series']['radiant_gold'])\n",
    "        t1_sum = t1.sum()\n",
    "        t1_mean = t1.mean()\n",
    "        t1_std = t1.std()\n",
    "        t1_median = np.median(t1)\n",
    "        \n",
    "        \n",
    "        delta_sum =  t_sum - p_sum\n",
    "        delta_mean = t_mean - p_mean\n",
    "        delta_std = t_std - p_std\n",
    "        delta_median = t_median - p_median\n",
    "        \n",
    "        delta1_sum =  t1_sum - p_sum\n",
    "        delta1_mean = t1_mean - p_mean\n",
    "        delta1_std = t1_std - p_std\n",
    "        delta1_median = t1_median - p_median\n",
    "        \n",
    "        \n",
    "        test_id.append(record['id'])\n",
    "        test_series.append([p_sum, p_mean, p_std, p_median, t_sum, t_mean, t_std, t_median, t1_sum, t1_mean, t1_std, t1_median, delta_sum, delta_mean, delta_std, delta_median, delta1_sum, delta1_mean, delta1_std, delta1_median])\n",
    "\n",
    "test_series = pd.DataFrame(test_series, index=test_id)\n",
    "test_series.columns = ['p_sum','p_mean','p_std','p_median','t_sum','t_mean','t_std','t_median', 't1_sum','t1_mean','t1_std','t1_median', 'delta_sum', 'delta_mean', 'delta_std', 'delta_median', 'delta1_sum', 'delta1_mean', 'delta1_std', 'delta1_median']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# level up times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110bf03b3c5a4154a287f0f5f436da62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 5.11 s, total: 1min 31s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_id_items = []\n",
    "train_id = []\n",
    "import json\n",
    "it = 0\n",
    "with open('data/dota2_skill_train.jsonlines') as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        record = json.loads(line)\n",
    "        \n",
    "        m = np.mean(record['level_up_times'])\n",
    "        s = np.std(record['level_up_times'])\n",
    "        med = np.median(record['level_up_times'])\n",
    "        ma =np.max(record['level_up_times'])\n",
    "        \n",
    "        train_id_items.append([m,s,med,ma])\n",
    "        train_id.append(record['id'])\n",
    "        \n",
    "df_train = pd.DataFrame(train_id_items, index=train_id)\n",
    "df_train.columns = ['l_u_mean', 'l_u_std', 'l_u_med', 'l_u_ma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60cd9a8855249fab240ceebbb64606b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_id_items = []\n",
    "test_id = []\n",
    "import json\n",
    "it = 0\n",
    "with open('data/dota2_skill_test.jsonlines') as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        record = json.loads(line)\n",
    "        \n",
    "        m = np.mean(record['level_up_times'])\n",
    "        s = np.std(record['level_up_times'])\n",
    "        med = np.median(record['level_up_times'])\n",
    "        ma =np.max(record['level_up_times'])\n",
    "        \n",
    "        test_id_items.append([m,s,med,ma])\n",
    "        test_id.append(record['id'])\n",
    "\n",
    "df_test = pd.DataFrame(test_id_items, index=test_id)\n",
    "df_test.columns = ['l_u_mean', 'l_u_std', 'l_u_med', 'l_u_ma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# radiant_heroes, dire_heroes, heroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb55bb3d7994697bcae6427c93046a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_teammates = []\n",
    "train_id = []\n",
    "import json\n",
    "it = 0\n",
    "with open('data/dota2_skill_train.jsonlines') as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        record = json.loads(line)\n",
    "        \n",
    "        train_id.append(record['id'])\n",
    "        train_teammates.append(record['{}_heroes'.format(record['player_team'])])\n",
    "        \n",
    "train_teammates_id = pd.DataFrame(train_teammates, index=train_id)\n",
    "train_teammates= pd.DataFrame(index=train_id)\n",
    "\n",
    "h0 = OneHotEncoder().fit_transform(train_teammates_id[0].values.reshape(-1,1))\n",
    "h1 = OneHotEncoder().fit_transform(train_teammates_id[1].values.reshape(-1,1))\n",
    "h2 = OneHotEncoder().fit_transform(train_teammates_id[2].values.reshape(-1,1))\n",
    "h3 = OneHotEncoder().fit_transform(train_teammates_id[3].values.reshape(-1,1))\n",
    "h4 = OneHotEncoder().fit_transform(train_teammates_id[4].values.reshape(-1,1))\n",
    "\n",
    "df_h0 = pd.DataFrame(h0.toarray(), index=train_id)\n",
    "df_h1 = pd.DataFrame(h1.toarray(), index=train_id)\n",
    "df_h2 = pd.DataFrame(h2.toarray(), index=train_id)\n",
    "df_h3 = pd.DataFrame(h3.toarray(), index=train_id)\n",
    "df_h4 = pd.DataFrame(h4.toarray(), index=train_id)\n",
    "\n",
    "train_teammates = df_h0 + df_h1 + df_h2 + df_h3 + df_h4\n",
    "train_teammates = train_teammates.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4e07b2661f47df90834ede3ee1e519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_teammates = []\n",
    "test_id = []\n",
    "import json\n",
    "it = 0\n",
    "with open('data/dota2_skill_test.jsonlines') as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        record = json.loads(line)\n",
    "        \n",
    "        test_id.append(record['id'])\n",
    "        test_teammates.append(record['{}_heroes'.format(record['player_team'])])\n",
    "        \n",
    "test_teammates_id = pd.DataFrame(test_teammates, index=test_id)\n",
    "test_teammates= pd.DataFrame(index=test_id)\n",
    "\n",
    "h0 = OneHotEncoder().fit_transform(test_teammates_id[0].values.reshape(-1,1))\n",
    "h1 = OneHotEncoder().fit_transform(test_teammates_id[1].values.reshape(-1,1))\n",
    "h2 = OneHotEncoder().fit_transform(test_teammates_id[2].values.reshape(-1,1))\n",
    "h3 = OneHotEncoder().fit_transform(test_teammates_id[3].values.reshape(-1,1))\n",
    "h4 = OneHotEncoder().fit_transform(test_teammates_id[4].values.reshape(-1,1))\n",
    "\n",
    "df_h0 = pd.DataFrame(h0.toarray(), index=test_id)\n",
    "df_h1 = pd.DataFrame(h1.toarray(), index=test_id)\n",
    "df_h2 = pd.DataFrame(h2.toarray(), index=test_id)\n",
    "df_h3 = pd.DataFrame(h3.toarray(), index=test_id)\n",
    "df_h4 = pd.DataFrame(h4.toarray(), index=test_id)\n",
    "\n",
    "test_teammates = df_h0 + df_h1 + df_h2 + df_h3 + df_h4\n",
    "test_teammates = test_teammates.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heroes_agi = {}\n",
    "for ind, agi in zip(heroes.index, heroes.agi_gain):\n",
    "    heroes_agi[ind] = agi\n",
    "    \n",
    "heroes_attack_range = {}\n",
    "for ind, att in zip(heroes.index, heroes.attack_range):\n",
    "    heroes_attack_range[ind] = att\n",
    "    \n",
    "heroes_attack_rate = {}\n",
    "for ind, att_r in zip(heroes.index, heroes.attack_rate):\n",
    "    heroes_attack_rate[ind] = att_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8b44f0d0ff44f88ac8bbe1c03e9429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99871), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_id = []\n",
    "train_tm_stats = []\n",
    "for p_id in tqdm_notebook(train_teammates_id.index):\n",
    "    tm_agi = []\n",
    "    tm_attack_range = []\n",
    "    tm_attack_rate = []\n",
    "    tm_winrate = []\n",
    "    \n",
    "    for tm in train_teammates_id[train_teammates_id.index == p_id].values[0]:\n",
    "        tm_agi.append(heroes_agi[tm])\n",
    "        tm_attack_range.append(heroes_attack_range[tm])\n",
    "        tm_attack_rate.append(heroes_attack_rate[tm])\n",
    "        \n",
    "        #tm_winrate.append(heroes[heroes.index == tm]['winrate'].values[0])\n",
    "    train_id.append(p_id)\n",
    "\n",
    "    tm_agi_mean = np.array(tm_agi).mean()\n",
    "    tm_attack_range_mean = np.array(tm_attack_range).mean()\n",
    "    tm_attack_rate_mean = np.array(tm_attack_rate).mean()\n",
    "    #tm_winrate_mean = np.array(tm_winrate).mean()\n",
    "    \n",
    "    tm_agi_std = np.array(tm_agi).std()\n",
    "    tm_attack_range_std = np.array(tm_attack_range).std()\n",
    "    tm_attack_rate_std = np.array(tm_attack_rate).std()\n",
    "    #tm_winrate_std = np.array(tm_winrate).std()\n",
    "    \n",
    "    \n",
    "    train_tm_stats.append([tm_agi_mean, tm_attack_range_mean, tm_attack_rate_mean,\n",
    "                        tm_agi_std, tm_attack_range_std, tm_attack_rate_std]) #   tm_winrate_mean, tm_winrate_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heroes from Open Dota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=heroes.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69fba77a1a8a49db9e859853d78f2de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=117), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for index in tqdm_notebook(heroes.index):\n",
    "    a = requests.get('https://api.opendota.com/api/benchmarks/?hero_id={}'.format(index)).json()\n",
    "    for inf in a['result'].keys():\n",
    "        s = pd.DataFrame(a['result'][inf])['value'].values\n",
    "        df.at[index, '{}_median'.format(inf)] = np.median(s)\n",
    "        df.at[index, '{}_mean'.format(inf)] = np.mean(s)\n",
    "        df.at[index, '{}_std'.format(inf)] = np.std(s)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heroes_with_b = heroes.join(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heroes_with_b.to_csv('heroes_with_open_dota.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('heroes_with_open_dota.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(54, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train.skilled\n",
    "X = train\n",
    "X = X.drop(['skilled', 'player_team', 'winner_team'], axis=1)\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0351a28b63434689a76e84db9c5270ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.624\n",
      "[1,  4000] loss: 0.621\n",
      "[1,  6000] loss: 0.611\n",
      "[1,  8000] loss: 0.603\n",
      "[1, 10000] loss: 0.601\n",
      "[1, 12000] loss: 0.580\n",
      "[1, 14000] loss: 0.602\n",
      "[1, 16000] loss: 0.616\n",
      "[1, 18000] loss: 0.603\n",
      "[1, 20000] loss: 0.596\n",
      "[1, 22000] loss: 0.600\n",
      "[1, 24000] loss: 0.608\n",
      "[1, 26000] loss: 0.591\n",
      "[1, 28000] loss: 0.597\n",
      "[1, 30000] loss: 0.602\n",
      "[1, 32000] loss: 0.595\n",
      "[1, 34000] loss: 0.588\n",
      "[1, 36000] loss: 0.594\n",
      "[1, 38000] loss: 0.582\n",
      "[1, 40000] loss: 0.577\n",
      "[1, 42000] loss: 0.607\n",
      "[1, 44000] loss: 0.578\n",
      "[1, 46000] loss: 0.590\n",
      "[1, 48000] loss: 0.597\n",
      "[1, 50000] loss: 0.588\n",
      "[1, 52000] loss: 0.573\n",
      "[1, 54000] loss: 0.587\n",
      "[1, 56000] loss: 0.583\n",
      "[1, 58000] loss: 0.587\n",
      "[1, 60000] loss: 0.581\n",
      "[1, 62000] loss: 0.591\n",
      "[1, 64000] loss: 0.581\n",
      "[1, 66000] loss: 0.606\n",
      "[1, 68000] loss: 0.590\n",
      "[1, 70000] loss: 0.579\n",
      "[1, 72000] loss: 0.583\n",
      "[1, 74000] loss: 0.582\n",
      "[1, 76000] loss: 0.583\n",
      "[1, 78000] loss: 0.587\n",
      "[1, 80000] loss: 0.598\n",
      "[1, 82000] loss: 0.570\n",
      "[1, 84000] loss: 0.574\n",
      "[1, 86000] loss: 0.597\n",
      "[1, 88000] loss: 0.566\n",
      "[1, 90000] loss: 0.591\n",
      "[1, 92000] loss: 0.590\n",
      "[1, 94000] loss: 0.588\n",
      "[1, 96000] loss: 0.574\n",
      "[1, 98000] loss: 0.599\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e229519d4d488a8bf2e991843cd8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  2000] loss: 0.589\n",
      "[2,  4000] loss: 0.597\n",
      "[2,  6000] loss: 0.587\n",
      "[2,  8000] loss: 0.584\n",
      "[2, 10000] loss: 0.584\n",
      "[2, 12000] loss: 0.564\n",
      "[2, 14000] loss: 0.593\n",
      "[2, 16000] loss: 0.607\n",
      "[2, 18000] loss: 0.590\n",
      "[2, 20000] loss: 0.587\n",
      "[2, 22000] loss: 0.592\n",
      "[2, 24000] loss: 0.599\n",
      "[2, 26000] loss: 0.581\n",
      "[2, 28000] loss: 0.588\n",
      "[2, 30000] loss: 0.596\n",
      "[2, 32000] loss: 0.588\n",
      "[2, 34000] loss: 0.580\n",
      "[2, 36000] loss: 0.587\n",
      "[2, 38000] loss: 0.576\n",
      "[2, 40000] loss: 0.570\n",
      "[2, 42000] loss: 0.602\n",
      "[2, 44000] loss: 0.572\n",
      "[2, 46000] loss: 0.585\n",
      "[2, 48000] loss: 0.591\n",
      "[2, 50000] loss: 0.582\n",
      "[2, 52000] loss: 0.568\n",
      "[2, 54000] loss: 0.583\n",
      "[2, 56000] loss: 0.578\n",
      "[2, 58000] loss: 0.583\n",
      "[2, 60000] loss: 0.576\n",
      "[2, 62000] loss: 0.589\n",
      "[2, 64000] loss: 0.577\n",
      "[2, 66000] loss: 0.602\n",
      "[2, 68000] loss: 0.586\n",
      "[2, 70000] loss: 0.576\n",
      "[2, 72000] loss: 0.578\n",
      "[2, 74000] loss: 0.578\n",
      "[2, 76000] loss: 0.579\n",
      "[2, 78000] loss: 0.584\n",
      "[2, 80000] loss: 0.594\n",
      "[2, 82000] loss: 0.568\n",
      "[2, 84000] loss: 0.571\n",
      "[2, 86000] loss: 0.595\n",
      "[2, 88000] loss: 0.563\n",
      "[2, 90000] loss: 0.589\n",
      "[2, 92000] loss: 0.587\n",
      "[2, 94000] loss: 0.586\n",
      "[2, 96000] loss: 0.571\n",
      "[2, 98000] loss: 0.597\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in tqdm_notebook(enumerate(zip(X,y))):\n",
    "        \n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = torch.Tensor(inputs), torch.Tensor([labels])\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "from tqdm import tqdm_notebook\n",
    "import catboost\n",
    "import lightgbm\n",
    "import xgboost\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier, Ridge\n",
    "from sklearn.model_selection import ShuffleSplit, KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm1 =  lightgbm.LGBMClassifier(n_estimators=1500, learning_rate=0.1, max_depth=12, reg_alpha=9, min_child_weight=8, n_jobs=-1, random_state=1)\n",
    "lgbm2 =  lightgbm.LGBMClassifier(n_estimators=1000, learning_rate=0.1, max_depth=6, reg_alpha=10, min_child_weight=5, n_jobs=-1, random_state=1)\n",
    "xgb1 = xgboost.XGBClassifier(learning_rate=0.1, n_estimators=1000, max_depth=4, min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8, reg_alpha=4, objective= 'binary:logistic', nthread=-1, scale_pos_weight=1, seed=27)\n",
    "xgb2 = xgboost.XGBClassifier(learning_rate=0.1, n_estimators=1000, max_depth=8, min_child_weight=6, gamma=0, subsample=0.8, reg_alpha=9, nthread=6, seed=27)\n",
    "cb = catboost.CatBoostClassifier(depth=8, n_estimators=1500, verbose=False) \n",
    "rg = Ridge(alpha=0.0001)\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for clf in tqdm_notebook([lgbm1, lgbm2, xgb1, xgb2, cb, rg, reg]):\n",
    "    clf.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### meta features for train meta and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds1 = lgbm1.predict(valid)\n",
    "preds2 = lgbm2.predict(valid)\n",
    "preds3 = xgb1.predict(valid)\n",
    "preds4 = xgb2.predict(valid)\n",
    "preds5 = cb.predict(valid)\n",
    "preds6 = rg.predict(valid)\n",
    "preds7 = reg.predict(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds1 = lgbm1.predict(X_test)\n",
    "test_preds2 = lgbm2.predict(X_test)\n",
    "test_preds3 = xgb1.predict(X_test)\n",
    "test_preds4 = xgb2.predict(X_test)\n",
    "test_preds5 = cb.predict(X_test)\n",
    "test_preds6 = rg.predict(X_test)\n",
    "test_preds7 = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st_preds = np.column_stack((preds1, preds2, preds3, preds4, preds5, preds6, preds7))\n",
    "st_preds_test = np.column_stack((test_preds1, test_preds2, test_preds3, test_preds4, test_preds5, test_preds6, test_preds7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unite meta with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_meta_val = pd.DataFrame(st_preds, index=valid.index)\n",
    "df_meta_test = pd.DataFrame(st_preds_test, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_valid = pd.concat([valid, df_meta_val], axis=1, join_axes=[valid.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_X_test = pd.concat([X_test, df_meta_test], axis=1, join_axes=[X_test.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_model = LinearRegression()\n",
    "meta_model.fit(meta_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans = meta_model.predict(meta_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, (ans > 0.5).astype('int') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bags = 30\n",
    "seed = 1 \n",
    "\n",
    "bagged_prediction = np.zeros(X_test.shape[0])\n",
    "\n",
    "for n in tqdm_notebook(range(0,bags)):\n",
    "    my_model.set_params(random_state= seed + n)\n",
    "    my_model.fit(X_train, y_train)\n",
    "    preds = my_model.predict(X_test)\n",
    "    bagged_prediction += preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bagged_prediction /= bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(bagged_prediction > 0.5).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, (bagged_prediction > 0.5).astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "my_model = RandomForestClassifier(random_state=0).fit(X_train, y_train)\n",
    "perm = PermutationImportance(clf_3, random_state=1).fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eli5.show_weights(perm, feature_names = data_train.columns.tolist(), top=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
